---
title: "Mapping standing deadwood from RGB drone imagery"
date: "12 Oktober 2020"
output:
  bookdown::html_document2:
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
1+1
```


<br><br>

In this tutorial you will learn how to map deadwood from RGB drone imagery using Deep Learning.
The data used in this tutorial can be found [here](https://bwstaff-my.sharepoint.com/personal/felix_schiefer_bwstaff_de/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Ffelix%5Fschiefer%5Fbwstaff%5Fde%2FDocuments%2FRS%5FTutorials%2FDeepLearning)

In this tutorial we will use R.

A step-by-step guide how to install tensorflow can be found [here]() 

<br><br>

# Overview {#overview}


1. [Data acquisition](#data)
    + [UAV flights](#UAV)
    + [Delineation](#label)
2. [Prepare the data](#prep)
    + [Tiling](#tile)
    + [Data spliting](#split)
    + [Tfdataset input pipeline](#pipeline)
3. [CNN-based deadwood mapping](#CNN)
    + [U-net](#unet)
    + [Training](#train)
    + [Accuracy assesment](#accuracy)
    + [Prediction](#prediction)

<br><br>

***

# Data acquisiton {#data}

### UAV flights {#UAV}

### Data labeling {#label}


For this tutorial you don't need to conduct any UAV flights or reference data labeling and you can go directly to this [link](https://bwstaff-my.sharepoint.com/personal/felix_schiefer_bwstaff_de/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Ffelix%5Fschiefer%5Fbwstaff%5Fde%2FDocuments%2FRS%5FTutorials%2FDeepLearning) and download the data. The UAV imagery is stored in the subfolder *UAV*, whereas the deadwood polygons can be found in the subfolder *delineation*. 

<br><br>

***

# Data preparation {#prep}


### Tiling {#tile}

### Data spliting {#split}

### Input pipeline {#pipeline}

<br><br>

# CNN-based deadwood mapping {#CNN}

### U-net {#unet}

### Training {#train}

### Accuracy assesment {#assessment}

### Prediction {#prediction}